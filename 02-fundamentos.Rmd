# Fundamentos Descriptivos {#fundamentos}


```{r setup, include=FALSE}
# Instalar el paquete si no lo tienes


# Cargar el paquete
library(jsonlite)
library(paqueteMODELOS)
library(naniar)
library(mice)
library(xtable)
library(kableExtra)
library(corrplot)
library(openxlsx)
library(dplyr)
library(factoextra)
library(ca)
library(FactoMineR)
library(leaflet)
library(plotly)
library(ggplot2)
library(dplyr)
library(lmtest)
library(gridExtra)
library(DiagrammeR)
library(caret)
library(pROC)
library(tidyverse)
library(zoo)      # Para promedios móviles
library(lubridate)
library(ggplot2)
library(tsibble)  # Para manejo de series de tiempo
library(forecast) # Para descomposición
library(httr)
library(jsonlite)
library(readxl)



# URL del archivo JSON
#url <- "https://www.datos.gov.co/resource/db67-sbus.json"

# Solicitar el contenido del JSON
#response <- GET(url)

# Convertir el contenido JSON a un dataframe y almacenarlo en 'datos'
#datos <- fromJSON(content(response, "text", encoding = "UTF-8"))


datos <- read_excel("data/datos.xlsx")

# Verificar los primeros registros
head(datos)

```


**Variables de la base de datos**

```{r warning=FALSE}
colnames(datos)
```

**3 primeros Registros de la base de datos** 

```{r warning=FALSE}
head(datos,3)
```
**número total de registros**

```{r warning=FALSE}
nrow(datos)
```


### EXPLORACION DE LOS DATOS

Se inicia con la exploracion del Dataset, asi como con el resumen estadistico

**Estructura del dataset**

```{r warning=FALSE}
# 
kable(head(datos), format = "markdown")

```


**Se realiza la verificación de valores nulos por cada una de las variables que conforman la data.**

```{r warning=FALSE}
# Verificar valores nulos
sum(is.na(datos))

# Verificar la cantidad de valores nulos por columna
colSums(is.na(datos))

grafico_faltantes <-md.pattern(datos, rotate.names = TRUE)

```


```{r}

df <- datos %>%
  mutate(
    numerocasos = as.numeric(numerocasos),
    numeropoblacionobjetivo = as.numeric(numeropoblacionobjetivo),
    tasa_suicidios = numerocasos / numeropoblacionobjetivo * 1000
  )

unique(df$numerocasos)
unique(df$numeropoblacionobjetivo)

# Eliminar puntos (separadores de miles), reemplazar comas decimales si fuera el caso
df <- df %>%
  mutate(
    numerocasos = as.numeric(gsub("\\.", "", numerocasos)),
    numeropoblacionobjetivo = as.numeric(gsub("\\.", "", numeropoblacionobjetivo))
  )

df <- df %>%
  mutate(tasa_suicidios = numerocasos / numeropoblacionobjetivo * 100000)


# Agrupar por año
serie_anual <- df %>%
  group_by(anio) %>%
  summarise(tasa_promedio = mean(tasa_suicidios, na.rm = TRUE))

# Verificar la serie
print(serie_anual)

datos_agregados <- datos %>%
  group_by(anio) %>%
  summarise(casos = sum(numerocasos))

ggplot(datos_agregados, aes(x = anio, y = casos)) +
  geom_line(color = "steelblue") +
  geom_point() +
  labs(title = "Casos de suicidio por año en Antioquia (2005–2022)",
       x = "Año", y = "Número de casos") +
  theme_minimal()


datos_agregados$movil_3 <- rollmean(datos_agregados$casos, k = 2, fill = NA)

ggplot(datos_agregados, aes(x = anio)) +
  geom_line(aes(y = casos), color = "grey") +
  geom_line(aes(y = movil_3), color = "red") +
  labs(title = "Promedio móvil de 3 años", y = "Casos")


ts_suicidios <- ts(datos_agregados$casos, start = 2005, frequency = 1)

acf(ts_suicidios, main = "Función de autocorrelación (ACF)")

```
